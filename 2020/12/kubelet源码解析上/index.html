<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.79.0 with theme Tranquilpeak 0.4.8-BETA">
<meta name="author" content="游">
<meta name="keywords" content="k8s, kubelet">
<meta name="description" content="kubelet介绍 在k8s集群中的每个节点上都运行着一个kubelet服务进程，其主要负责向apiserver注册节点、管理pod及pod中的容器，并通过 cAdvisor 监控节点和容器的资源。
 节点管理：节点注册、节点状态更新(定期心跳) pod管理：接受来自apiserver、file、http等PodSpec，并确保这些 PodSpec 中描述的容器处于运行状态且运行状况良好 容器健康检查：通过ReadinessProbe、LivenessProbe两种探针检查容器健康状态 资源监控：通过 cAdvisor 获取其所在节点及容器的监控数据  深入kubelet工作原理 从上图可以看出kubelet的主要工作逻辑在SyncLoop控制循环中，处理pod更新事件、pod生命周期变化、周期sync事件、定时清理事件；SyncLoop旁还有处理其他逻辑的控制循环，例如处理pod状态同步的statusManager，处理健康检查的probeManager等。
下面将从kubelet源码来分析各个环节的处理逻辑。
kubelet代码(版本1.19)主要位于cmd/kubelet与pkg/kubelet下，首先看下kubelet启动流程与初始化
// kubelet依赖cobra命令行库，创建kubelet command并执行 cmd/kubelet/kubelet.go:34 func main() // 处理flags、configfile验证、初始化kubletServer/kubeletDeps(依赖注入)、信号处理ctx，调用run cmd/kubelet/app/server.go:113 func NewKubeletCommand() *cobra.Command // client(kube\event\heartbeat)、auth、cgroup、cadvisor、containerManager、runtime初始化(dockershim...)、healthz监听，调用RunKubelet cmd/kubelet/app/server.go:472 func run // 创建Kubelet关键结构体，执行Kubelet Run进入主循环，运行kubelet server、只读端口等 cmd/kubelet/app/server.go:1071 func RunKubelet // 先看下NewMainKubelet创建初始化Kubelet关键结构体函数 cmd/kubelet/kubelet.go:333 func NewMainKubelet(...){ // 创建PodConfig，watch apiserver、file、http等 if kubeDeps.PodConfig == nil { var err error kubeDeps.PodConfig, err = makePodSourceConfig(kubeCfg, kubeDeps, nodeName) if err != nil { return nil, err } } // 创建service informer、node、oom watcher // 创建Kubelet // 创建各种manager例如secret、configMap // 创建podManager，管理pod信息 klet.">


<meta property="og:description" content="kubelet介绍 在k8s集群中的每个节点上都运行着一个kubelet服务进程，其主要负责向apiserver注册节点、管理pod及pod中的容器，并通过 cAdvisor 监控节点和容器的资源。
 节点管理：节点注册、节点状态更新(定期心跳) pod管理：接受来自apiserver、file、http等PodSpec，并确保这些 PodSpec 中描述的容器处于运行状态且运行状况良好 容器健康检查：通过ReadinessProbe、LivenessProbe两种探针检查容器健康状态 资源监控：通过 cAdvisor 获取其所在节点及容器的监控数据  深入kubelet工作原理 从上图可以看出kubelet的主要工作逻辑在SyncLoop控制循环中，处理pod更新事件、pod生命周期变化、周期sync事件、定时清理事件；SyncLoop旁还有处理其他逻辑的控制循环，例如处理pod状态同步的statusManager，处理健康检查的probeManager等。
下面将从kubelet源码来分析各个环节的处理逻辑。
kubelet代码(版本1.19)主要位于cmd/kubelet与pkg/kubelet下，首先看下kubelet启动流程与初始化
// kubelet依赖cobra命令行库，创建kubelet command并执行 cmd/kubelet/kubelet.go:34 func main() // 处理flags、configfile验证、初始化kubletServer/kubeletDeps(依赖注入)、信号处理ctx，调用run cmd/kubelet/app/server.go:113 func NewKubeletCommand() *cobra.Command // client(kube\event\heartbeat)、auth、cgroup、cadvisor、containerManager、runtime初始化(dockershim...)、healthz监听，调用RunKubelet cmd/kubelet/app/server.go:472 func run // 创建Kubelet关键结构体，执行Kubelet Run进入主循环，运行kubelet server、只读端口等 cmd/kubelet/app/server.go:1071 func RunKubelet // 先看下NewMainKubelet创建初始化Kubelet关键结构体函数 cmd/kubelet/kubelet.go:333 func NewMainKubelet(...){ // 创建PodConfig，watch apiserver、file、http等 if kubeDeps.PodConfig == nil { var err error kubeDeps.PodConfig, err = makePodSourceConfig(kubeCfg, kubeDeps, nodeName) if err != nil { return nil, err } } // 创建service informer、node、oom watcher // 创建Kubelet // 创建各种manager例如secret、configMap // 创建podManager，管理pod信息 klet.">
<meta property="og:type" content="article">
<meta property="og:title" content="kubelet源码解析(上)">
<meta name="twitter:title" content="kubelet源码解析(上)">
<meta property="og:url" content="https://itech.red/2020/12/kubelet%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%8A/">
<meta property="twitter:url" content="https://itech.red/2020/12/kubelet%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%8A/">
<meta property="og:site_name" content="平凡世界">
<meta property="og:description" content="kubelet介绍 在k8s集群中的每个节点上都运行着一个kubelet服务进程，其主要负责向apiserver注册节点、管理pod及pod中的容器，并通过 cAdvisor 监控节点和容器的资源。
 节点管理：节点注册、节点状态更新(定期心跳) pod管理：接受来自apiserver、file、http等PodSpec，并确保这些 PodSpec 中描述的容器处于运行状态且运行状况良好 容器健康检查：通过ReadinessProbe、LivenessProbe两种探针检查容器健康状态 资源监控：通过 cAdvisor 获取其所在节点及容器的监控数据  深入kubelet工作原理 从上图可以看出kubelet的主要工作逻辑在SyncLoop控制循环中，处理pod更新事件、pod生命周期变化、周期sync事件、定时清理事件；SyncLoop旁还有处理其他逻辑的控制循环，例如处理pod状态同步的statusManager，处理健康检查的probeManager等。
下面将从kubelet源码来分析各个环节的处理逻辑。
kubelet代码(版本1.19)主要位于cmd/kubelet与pkg/kubelet下，首先看下kubelet启动流程与初始化
// kubelet依赖cobra命令行库，创建kubelet command并执行 cmd/kubelet/kubelet.go:34 func main() // 处理flags、configfile验证、初始化kubletServer/kubeletDeps(依赖注入)、信号处理ctx，调用run cmd/kubelet/app/server.go:113 func NewKubeletCommand() *cobra.Command // client(kube\event\heartbeat)、auth、cgroup、cadvisor、containerManager、runtime初始化(dockershim...)、healthz监听，调用RunKubelet cmd/kubelet/app/server.go:472 func run // 创建Kubelet关键结构体，执行Kubelet Run进入主循环，运行kubelet server、只读端口等 cmd/kubelet/app/server.go:1071 func RunKubelet // 先看下NewMainKubelet创建初始化Kubelet关键结构体函数 cmd/kubelet/kubelet.go:333 func NewMainKubelet(...){ // 创建PodConfig，watch apiserver、file、http等 if kubeDeps.PodConfig == nil { var err error kubeDeps.PodConfig, err = makePodSourceConfig(kubeCfg, kubeDeps, nodeName) if err != nil { return nil, err } } // 创建service informer、node、oom watcher // 创建Kubelet // 创建各种manager例如secret、configMap // 创建podManager，管理pod信息 klet.">
<meta name="twitter:description" content="kubelet介绍 在k8s集群中的每个节点上都运行着一个kubelet服务进程，其主要负责向apiserver注册节点、管理pod及pod中的容器，并通过 cAdvisor 监控节点和容器的资源。
 节点管理：节点注册、节点状态更新(定期心跳) pod管理：接受来自apiserver、file、http等PodSpec，并确保这些 PodSpec 中描述的容器处于运行状态且运行状况良好 容器健康检查：通过ReadinessProbe、LivenessProbe两种探针检查容器健康状态 资源监控：通过 cAdvisor 获取其所在节点及容器的监控数据  深入kubelet工作原理 从上图可以看出kubelet的主要工作逻辑在SyncLoop控制循环中，处理pod更新事件、pod生命周期变化、周期sync事件、定时清理事件；SyncLoop旁还有处理其他逻辑的控制循环，例如处理pod状态同步的statusManager，处理健康检查的probeManager等。
下面将从kubelet源码来分析各个环节的处理逻辑。
kubelet代码(版本1.19)主要位于cmd/kubelet与pkg/kubelet下，首先看下kubelet启动流程与初始化
// kubelet依赖cobra命令行库，创建kubelet command并执行 cmd/kubelet/kubelet.go:34 func main() // 处理flags、configfile验证、初始化kubletServer/kubeletDeps(依赖注入)、信号处理ctx，调用run cmd/kubelet/app/server.go:113 func NewKubeletCommand() *cobra.Command // client(kube\event\heartbeat)、auth、cgroup、cadvisor、containerManager、runtime初始化(dockershim...)、healthz监听，调用RunKubelet cmd/kubelet/app/server.go:472 func run // 创建Kubelet关键结构体，执行Kubelet Run进入主循环，运行kubelet server、只读端口等 cmd/kubelet/app/server.go:1071 func RunKubelet // 先看下NewMainKubelet创建初始化Kubelet关键结构体函数 cmd/kubelet/kubelet.go:333 func NewMainKubelet(...){ // 创建PodConfig，watch apiserver、file、http等 if kubeDeps.PodConfig == nil { var err error kubeDeps.PodConfig, err = makePodSourceConfig(kubeCfg, kubeDeps, nodeName) if err != nil { return nil, err } } // 创建service informer、node、oom watcher // 创建Kubelet // 创建各种manager例如secret、configMap // 创建podManager，管理pod信息 klet.">
<meta property="og:locale" content="zh-cn">

  
    <meta property="article:published_time" content="2020-12-31T17:13:30">
  
  
    <meta property="article:modified_time" content="2020-12-31T17:13:30">
  
  
  
    
      <meta property="article:section" content="k8s">
    
  
  


<meta name="twitter:card" content="summary">











  <meta property="og:image" content="https://avatars3.githubusercontent.com/u/6330242?v=3&s=460">
  <meta property="twitter:image" content="https://avatars3.githubusercontent.com/u/6330242?v=3&s=460">


    <title>kubelet源码解析(上)</title>

    <link rel="icon" href="https://itech.red/favicon.png">
    

    

    <link rel="canonical" href="https://itech.red/2020/12/kubelet%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%8A/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="https://itech.red/css/style-twzjdbqhmnnacqs0pwwdzcdbt8yhv8giawvjqjmyfoqnvazl0dalmnhdkvp7.min.css" />
    
    

    
      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-82870469-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="5">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://itech.red/">平凡世界</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://itech.red/#about">
    
    
    
      
        <img class="header-picture" src="https://avatars3.githubusercontent.com/u/6330242?v=3&amp;s=460" alt="作者的图片" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="5">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://itech.red/#about">
          <img class="sidebar-profile-picture" src="https://avatars3.githubusercontent.com/u/6330242?v=3&amp;s=460" alt="作者的图片" />
        </a>
        <h4 class="sidebar-profile-name">游</h4>
        
          <h5 class="sidebar-profile-bio">沉下心，多坚持</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://itech.red/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">首页</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://itech.red/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">分类</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://itech.red/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">关于</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://itech.red/external_link">
    
      <i class="sidebar-button-icon fa fa-lg fa-external-link"></i>
      
      <span class="sidebar-button-desc">友链</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://itech.red/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="5"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      kubelet源码解析(上)
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2020-12-31T17:13:30&#43;08:00">
        
  
  
  
  
    2020-12-31 17:13:30
  

      </time>
    
    
  
  
    <span>发布在</span>
    
      <a class="category-link" href="https://itech.red/categories/k8s">k8s</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              <h3 id="kubelet介绍">kubelet介绍</h3>
<p>在k8s集群中的每个节点上都运行着一个kubelet服务进程，其主要负责向apiserver注册节点、管理pod及pod中的容器，并通过 cAdvisor 监控节点和容器的资源。</p>
<ul>
<li>节点管理：节点注册、节点状态更新(定期心跳)</li>
<li>pod管理：接受来自apiserver、file、http等PodSpec，并确保这些 PodSpec 中描述的容器处于运行状态且运行状况良好</li>
<li>容器健康检查：通过ReadinessProbe、LivenessProbe两种探针检查容器健康状态</li>
<li>资源监控：通过 cAdvisor 获取其所在节点及容器的监控数据</li>
</ul>
<h3 id="深入kubelet工作原理">深入kubelet工作原理</h3>
<p><img src="https://itech.red/images/kubelet.png" alt="kubelet"></p>
<p>从上图可以看出kubelet的主要工作逻辑在SyncLoop控制循环中，处理pod更新事件、pod生命周期变化、周期sync事件、定时清理事件；SyncLoop旁还有处理其他逻辑的控制循环，例如处理pod状态同步的statusManager，处理健康检查的probeManager等。</p>
<p>下面将从kubelet源码来分析各个环节的处理逻辑。</p>
<p>kubelet代码(版本1.19)主要位于cmd/kubelet与pkg/kubelet下，首先看下kubelet启动流程与初始化</p>
<pre><code>// kubelet依赖cobra命令行库，创建kubelet command并执行
cmd/kubelet/kubelet.go:34          func main()
// 处理flags、configfile验证、初始化kubletServer/kubeletDeps(依赖注入)、信号处理ctx，调用run
cmd/kubelet/app/server.go:113      func NewKubeletCommand() *cobra.Command
// client(kube\event\heartbeat)、auth、cgroup、cadvisor、containerManager、runtime初始化(dockershim...)、healthz监听，调用RunKubelet
cmd/kubelet/app/server.go:472      func run
// 创建Kubelet关键结构体，执行Kubelet Run进入主循环，运行kubelet server、只读端口等
cmd/kubelet/app/server.go:1071     func RunKubelet

// 先看下NewMainKubelet创建初始化Kubelet关键结构体函数
cmd/kubelet/kubelet.go:333
func NewMainKubelet(...){
    // 创建PodConfig，watch apiserver、file、http等
	if kubeDeps.PodConfig == nil {
		var err error
		kubeDeps.PodConfig, err = makePodSourceConfig(kubeCfg, kubeDeps, nodeName)
		if err != nil {
			return nil, err
		}
	}
	// 创建service informer、node、oom watcher
	// 创建Kubelet
	// 创建各种manager例如secret、configMap
	// 创建podManager，管理pod信息
	klet.podManager = kubepod.NewBasicPodManager(mirrorPodClient, secretManager, configMapManager)
	// 创建pleg
	klet.pleg = pleg.NewGenericPLEG(klet.containerRuntime, plegChannelCapacity, plegRelistPeriod, klet.podCache, clock.RealClock{})
	// 创建podWorker，syncPod为每个pod处理逻辑函数，在每个pod的goroutine中对pod更新进行同步
	klet.podWorkers = newPodWorkers(klet.syncPod, kubeDeps.Recorder, klet.workQueue,   klet.resyncInterval, backOffPeriod, klet.podCache
}

// Kubelet Run方法
pkg/kubelet/kubelet.go:1314
func (kl *Kubelet) Run(updates &lt;-chan kubetypes.PodUpdate) {
    // 初始化与runtime无关的逻辑，metrics、imageManager等
	if err := kl.initializeModules(); err != nil {
		kl.recorder.Eventf(kl.nodeRef, v1.EventTypeWarning, events.KubeletSetupFailed, err.Error())
		klog.Fatal(err)
	}
	// 启动volume manager
	go kl.volumeManager.Run(kl.sourcesReady, wait.NeverStop)

	if kl.kubeClient != nil {
		// 同步node状态
		go wait.Until(kl.syncNodeStatus, kl.nodeStatusUpdateFrequency, wait.NeverStop)
		go kl.fastStatusUpdateOnce()
		// 启动node lease
		go kl.nodeLeaseController.Run(wait.NeverStop)
	}
	// runtime首次初始化、定时更新
	go wait.Until(kl.updateRuntimeUp, 5*time.Second, wait.NeverStop)

	// 设置iptables规则
	if kl.makeIPTablesUtilChains {
		kl.initNetworkUtil()
	}

	// 启动podKiller，监听podKiller.podKillingCh
	go wait.Until(kl.podKiller.PerformPodKillingWork, 1*time.Second, wait.NeverStop)

	// 启动statusManager、probeManager
	kl.statusManager.Start()
	kl.probeManager.Start()

	// Start syncing RuntimeClasses if enabled.
	if kl.runtimeClassManager != nil {
		kl.runtimeClassManager.Start(wait.NeverStop)
	}

	// 启动pleg
	kl.pleg.Start()
	// 进入主循环
	kl.syncLoop(updates, kl)
}
</code></pre><p>上述代码逻辑实现kubelet参数、配置、信号处理注册，初始化依赖、Kubelet启动Manager, 进入各自manager处理逻辑，最后进入kubelet主循环逻辑，主循环有5个事件源</p>
<ul>
<li>configCh                    podConfig处理来自apiserver、file、http的pod更新，在创建Kubelet时初始化</li>
<li>handler                      liveness manager处理，在创建Kubelet时初始化，为statusManager的一部分</li>
<li>syncCh                      time定时同步pod</li>
<li>housekeepingCh         time定时清理pod</li>
<li>plegCh                      处理来自pleg的消息，在创建Kubelet时初始化，关于pleg可以看<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/pod-lifecycle-event-generator.md">这里</a>，简单说对容器状态感知由每个pod worker(goroutine)轮询改为pleg</li>
</ul>
<pre><code>// kubelet事件循环函数
pkg/kubelet/kubelet.go:1814
func (kl *Kubelet) syncLoopIteration(configCh &lt;-chan kubetypes.PodUpdate, handler SyncHandler,
	syncCh &lt;-chan time.Time, housekeepingCh &lt;-chan time.Time, plegCh &lt;-chan *pleg.PodLifecycleEvent) bool {
	select {
	// 处理来自apiserver、file、http的pod增删改查，最终走到Kubelet的syncPod处理
	case u, open := &lt;-configCh:
		if !open {
			klog.Errorf(&quot;Update channel is closed. Exiting the sync loop.&quot;)
			return false
		}
		switch u.Op {
		case kubetypes.ADD:
			klog.V(2).Infof(&quot;SyncLoop (ADD, %q): %q&quot;, u.Source, format.Pods(u.Pods))
			handler.HandlePodAdditions(u.Pods)
		case kubetypes.UPDATE:
			klog.V(2).Infof(&quot;SyncLoop (UPDATE, %q): %q&quot;, u.Source, format.PodsWithDeletionTimestamps(u.Pods))
			handler.HandlePodUpdates(u.Pods)
		case kubetypes.REMOVE:
			klog.V(2).Infof(&quot;SyncLoop (REMOVE, %q): %q&quot;, u.Source, format.Pods(u.Pods))
			handler.HandlePodRemoves(u.Pods)
		case kubetypes.RECONCILE:
			klog.V(4).Infof(&quot;SyncLoop (RECONCILE, %q): %q&quot;, u.Source, format.Pods(u.Pods))
			handler.HandlePodReconcile(u.Pods)
		case kubetypes.DELETE:
			klog.V(2).Infof(&quot;SyncLoop (DELETE, %q): %q&quot;, u.Source, format.Pods(u.Pods))
			handler.HandlePodUpdates(u.Pods)
		case kubetypes.SET:
			klog.Errorf(&quot;Kubelet does not support snapshot update&quot;)
		default:
			klog.Errorf(&quot;Invalid event type received: %d.&quot;, u.Op)
		}
		kl.sourcesReady.AddSource(u.Source)
    // 处理来自runtime的容器变化
	case e := &lt;-plegCh:
		if e.Type == pleg.ContainerStarted {
			kl.lastContainerStartedTime.Add(e.ID, time.Now())
		}
		if isSyncPodWorthy(e) {
			if pod, ok := kl.podManager.GetPodByUID(e.ID); ok {
				klog.V(2).Infof(&quot;SyncLoop (PLEG): %q, event: %#v&quot;, format.Pod(pod), e)
				handler.HandlePodSyncs([]*v1.Pod{pod})
			} else {
				klog.V(4).Infof(&quot;SyncLoop (PLEG): ignore irrelevant event: %#v&quot;, e)
			}
		}
		if e.Type == pleg.ContainerDied {
			if containerID, ok := e.Data.(string); ok {
				kl.cleanUpContainersInPod(e.ID, containerID)
			}
		}
	// 同步pod状态，最终走到Kubelet的syncPod处理
	case &lt;-syncCh:
		podsToSync := kl.getPodsToSync()
		if len(podsToSync) == 0 {
			break
		}
		klog.V(4).Infof(&quot;SyncLoop (SYNC): %d pods; %s&quot;, len(podsToSync), format.Pods(podsToSync))
		handler.HandlePodSyncs(podsToSync)
	// 处理probe fail，最终走到Kubelet的syncPod处理
	case update := &lt;-kl.livenessManager.Updates():
		if update.Result == proberesults.Failure {
			pod, ok := kl.podManager.GetPodByUID(update.PodUID)
			if !ok {
				klog.V(4).Infof(&quot;SyncLoop (container unhealthy): ignore irrelevant update: %#v&quot;, update)
				break
			}
			klog.V(1).Infof(&quot;SyncLoop (container unhealthy): %q&quot;, format.Pod(pod))
			handler.HandlePodSyncs([]*v1.Pod{pod})
		}
	case &lt;-housekeepingCh:
		if !kl.sourcesReady.AllReady() {
			klog.V(4).Infof(&quot;SyncLoop (housekeeping, skipped): sources aren't ready yet.&quot;)
		} else {
			klog.V(4).Infof(&quot;SyncLoop (housekeeping)&quot;)
			if err := handler.HandlePodCleanups(); err != nil {
				klog.Errorf(&quot;Failed cleaning pods: %v&quot;, err)
			}
		}
	}
	return true
}
</code></pre><p>对不同事件有不同的处理handler，大部分handler都会通过dispatchWork进入podWorkers.UpdatePod</p>
<pre><code>// podWorkers存储每个pod的goroutine并处理pod的update到对应goroutine
pkg/kubelet/pod_workers.go:200
func (p *podWorkers) UpdatePod(options *UpdatePodOptions) {
	pod := options.Pod
	uid := pod.UID
	var podUpdates chan UpdatePodOptions
	var exists bool

	p.podLock.Lock()
	defer p.podLock.Unlock()
	// pod是否已存在，如果不存在则创建channel，启动对应pod的goroutine
	if podUpdates, exists = p.podUpdates[uid]; !exists {
		podUpdates = make(chan UpdatePodOptions, 1)
		p.podUpdates[uid] = podUpdates
		go func() {
			defer runtime.HandleCrash()
			// pod处理函数
			p.managePodLoop(podUpdates)
		}()
	}
	// pod存在且空闲则写入，否则暂存最近的更新
	if !p.isWorking[pod.UID] {
		p.isWorking[pod.UID] = true
		podUpdates &lt;- *options
	} else {
		// SyncPodKill不会被覆盖
		if !found || update.UpdateType != kubetypes.SyncPodKill {
			p.lastUndeliveredWorkUpdate[pod.UID] = *options
		}
	}
}
// pod的处理goroutine，监听事件并调用Kubelet的方法syncPod处理
pkg/kubelet/pod_workers.go:158
func (p *podWorkers) managePodLoop(podUpdates &lt;-chan UpdatePodOptions) {
	var lastSyncTime time.Time
	for update := range podUpdates {
		err := func() error {
			podUID := update.Pod.UID
			status, err := p.podCache.GetNewerThan(podUID, lastSyncTime)
			if err != nil {
				p.recorder.Eventf(update.Pod, v1.EventTypeWarning, events.FailedSync, &quot;error determining status: %v&quot;, err)
				return err
			}
			// 调用Kubelet的方法syncPod
			err = p.syncPodFn(syncPodOptions{
				mirrorPod:      update.MirrorPod,
				pod:            update.Pod,
				podStatus:      status,
				killPodOptions: update.KillPodOptions,
				updateType:     update.UpdateType,
			})
			lastSyncTime = time.Now()
			return err
		}()
		if update.OnCompleteFunc != nil {
			update.OnCompleteFunc(err)
		}
		if err != nil {
			klog.Errorf(&quot;Error syncing pod %s (%q), skipping: %v&quot;, update.Pod.UID, format.Pod(update.Pod), err)
		}
		// 查看lastUndeliveredWorkUpdate是否有未处理的事件，继续处理
		p.wrapUp(update.Pod.UID, err)
	}
}
</code></pre><p>syncPod: 在交由runtime完成真正的处理逻辑之前，进行一些预处理</p>
<pre><code>func (kl *Kubelet) syncPod(o syncPodOptions) error {
	pod := o.pod
	mirrorPod := o.mirrorPod
	podStatus := o.podStatus
	updateType := o.updateType

	// 处理kill Pod
	if updateType == kubetypes.SyncPodKill {
		killPodOptions := o.killPodOptions
		if killPodOptions == nil || killPodOptions.PodStatusFunc == nil {
			return fmt.Errorf(&quot;kill pod options are required if update type is kill&quot;)
		}
		apiPodStatus := killPodOptions.PodStatusFunc(pod, podStatus)
		kl.statusManager.SetPodStatus(pod, apiPodStatus)
		// we kill the pod with the specified grace period since this is a termination
		if err := kl.killPod(pod, nil, podStatus, killPodOptions.PodTerminationGracePeriodSecondsOverride); err != nil {
			kl.recorder.Eventf(pod, v1.EventTypeWarning, events.FailedToKillPod, &quot;error killing pod: %v&quot;, err)
			// there was an error killing the pod, so we return that error directly
			utilruntime.HandleError(err)
			return err
		}
		return nil
	}
    ....
    // 是否能运行pod
	runnable := kl.canRunPod(pod)
	if !runnable.Admit {
		//不能回写container等待原因
		apiPodStatus.Reason = runnable.Reason
		apiPodStatus.Message = runnable.Message
		// Waiting containers are not creating.
		const waitingReason = &quot;Blocked&quot;
		for _, cs := range apiPodStatus.InitContainerStatuses {
			if cs.State.Waiting != nil {
				cs.State.Waiting.Reason = waitingReason
			}
		}
		for _, cs := range apiPodStatus.ContainerStatuses {
			if cs.State.Waiting != nil {
				cs.State.Waiting.Reason = waitingReason
			}
		}
	}

	// 更新statusManager pod状态
	kl.statusManager.SetPodStatus(pod, apiPodStatus)

	// 校验失败、标记删除、pod失败则kill pod
	if !runnable.Admit || pod.DeletionTimestamp != nil || apiPodStatus.Phase == v1.PodFailed {
		var syncErr error
		if err := kl.killPod(pod, nil, podStatus, nil); err != nil {
			kl.recorder.Eventf(pod, v1.EventTypeWarning, events.FailedToKillPod, &quot;error killing pod: %v&quot;, err)
			syncErr = fmt.Errorf(&quot;error killing pod: %v&quot;, err)
			utilruntime.HandleError(syncErr)
		} else {
			if !runnable.Admit {
				// There was no error killing the pod, but the pod cannot be run.
				// Return an error to signal that the sync loop should back off.
				syncErr = fmt.Errorf(&quot;pod cannot be run: %s&quot;, runnable.Message)
			}
		}
		return syncErr
	}

	// network plugin是否ready
	if err := kl.runtimeState.networkErrors(); err != nil &amp;&amp; !kubecontainer.IsHostNetworkPod(pod) {
		kl.recorder.Eventf(pod, v1.EventTypeWarning, events.NetworkNotReady, &quot;%s: %v&quot;, NetworkNotReadyErrorMsg, err)
		return fmt.Errorf(&quot;%s: %v&quot;, NetworkNotReadyErrorMsg, err)
	}

	// pod crgoup创建
	pcm := kl.containerManager.NewPodContainerManager()
	// 检查pod是否已经Terminate
	if !kl.podIsTerminated(pod) {
		// When the kubelet is restarted with the cgroups-per-qos
		// flag enabled, all the pod's running containers
		// should be killed intermittently and brought back up
		// under the qos cgroup hierarchy.
		// Check if this is the pod's first sync
		firstSync := true
		for _, containerStatus := range apiPodStatus.ContainerStatuses {
			if containerStatus.State.Running != nil {
				firstSync = false
				break
			}
		}
		// Don't kill containers in pod if pod's cgroups already
		// exists or the pod is running for the first time
		podKilled := false
		if !pcm.Exists(pod) &amp;&amp; !firstSync {
			if err := kl.killPod(pod, nil, podStatus, nil); err == nil {
				podKilled = true
			}
		}
		// Create and Update pod's Cgroups
		// Don't create cgroups for run once pod if it was killed above
		// The current policy is not to restart the run once pods when
		// the kubelet is restarted with the new flag as run once pods are
		// expected to run only once and if the kubelet is restarted then
		// they are not expected to run again.
		// We don't create and apply updates to cgroup if its a run once pod and was killed above
		if !(podKilled &amp;&amp; pod.Spec.RestartPolicy == v1.RestartPolicyNever) {
			if !pcm.Exists(pod) {
				if err := kl.containerManager.UpdateQOSCgroups(); err != nil {
					klog.V(2).Infof(&quot;Failed to update QoS cgroups while syncing pod: %v&quot;, err)
				}
				if err := pcm.EnsureExists(pod); err != nil {
					kl.recorder.Eventf(pod, v1.EventTypeWarning, events.FailedToCreatePodContainer, &quot;unable to ensure pod container exists: %v&quot;, err)
					return fmt.Errorf(&quot;failed to ensure that the pod: %v cgroups exist and are correctly applied: %v&quot;, pod.UID, err)
				}
			}
		}
	}

	// 如果是mirrorPod进入mirrorPod处理逻辑
	if kubetypes.IsStaticPod(pod) {
		podFullName := kubecontainer.GetPodFullName(pod)
		deleted := false
		if mirrorPod != nil {
			if mirrorPod.DeletionTimestamp != nil || !kl.podManager.IsMirrorPodOf(mirrorPod, pod) {
				// The mirror pod is semantically different from the static pod. Remove
				// it. The mirror pod will get recreated later.
				klog.Infof(&quot;Trying to delete pod %s %v&quot;, podFullName, mirrorPod.ObjectMeta.UID)
				var err error
				deleted, err = kl.podManager.DeleteMirrorPod(podFullName, &amp;mirrorPod.ObjectMeta.UID)
				if deleted {
					klog.Warningf(&quot;Deleted mirror pod %q because it is outdated&quot;, format.Pod(mirrorPod))
				} else if err != nil {
					klog.Errorf(&quot;Failed deleting mirror pod %q: %v&quot;, format.Pod(mirrorPod), err)
				}
			}
		}
		if mirrorPod == nil || deleted {
			node, err := kl.GetNode()
			if err != nil || node.DeletionTimestamp != nil {
				klog.V(4).Infof(&quot;No need to create a mirror pod, since node %q has been removed from the cluster&quot;, kl.nodeName)
			} else {
				klog.V(4).Infof(&quot;Creating a mirror pod for static pod %q&quot;, format.Pod(pod))
				if err := kl.podManager.CreateMirrorPod(pod); err != nil {
					klog.Errorf(&quot;Failed creating a mirror pod for %q: %v&quot;, format.Pod(pod), err)
				}
			}
		}
	}

	// 准备pod文件目录
	if err := kl.makePodDataDirs(pod); err != nil {
		kl.recorder.Eventf(pod, v1.EventTypeWarning, events.FailedToMakePodDataDirectories, &quot;error making pod data directories: %v&quot;, err)
		klog.Errorf(&quot;Unable to make pod data directories for pod %q: %v&quot;, format.Pod(pod), err)
		return err
	}

	// 等待挂载volumes
	if !kl.podIsTerminated(pod) {
		// Wait for volumes to attach/mount
		if err := kl.volumeManager.WaitForAttachAndMount(pod); err != nil {
			kl.recorder.Eventf(pod, v1.EventTypeWarning, events.FailedMountVolume, &quot;Unable to attach or mount volumes: %v&quot;, err)
			klog.Errorf(&quot;Unable to attach or mount volumes for pod %q: %v; skipping pod&quot;, format.Pod(pod), err)
			return err
		}
	}

	// Fetch the pull secrets for the pod
	pullSecrets := kl.getPullSecretsForPod(pod)

	// 调用runtime处理pod
	result := kl.containerRuntime.SyncPod(pod, podStatus, pullSecrets, kl.backOff)
	kl.reasonCache.Update(pod.UID, result)
	if err := result.Error(); err != nil {
		// Do not return error if the only failures were pods in backoff
		for _, r := range result.SyncResults {
			if r.Error != kubecontainer.ErrCrashLoopBackOff &amp;&amp; r.Error != images.ErrImagePullBackOff {
				// Do not record an event here, as we keep all event logging for sync pod failures
				// local to container runtime so we get better errors
				return err
			}
		}
		return nil
	}
	return nil
}
</code></pre>
              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
            
            <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">下一篇</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://itech.red/2020/12/k8s-conformance-test%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/" data-tooltip="k8s conformance test问题记录">
              
                  <span class="hide-xs hide-sm text-small icon-mr">上一篇</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

            
              
                
<div id="lv-container" data-id="city" data-uid="MTAyMC80ODIxMS8yNDcwNw==">
<script type="text/javascript">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
</script>
<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
</div>


              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2021 <a href="https://github.com/ThinkMo">ThinkMo</a>. All Rights Reserved
  </span>
  <div class="busuanzi-count">
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  </div>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
        <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml">下一篇</span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="https://itech.red/2020/12/k8s-conformance-test%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/" data-tooltip="k8s conformance test问题记录">
              
                  <span class="hide-xs hide-sm text-small icon-mr">上一篇</span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="5">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://avatars3.githubusercontent.com/u/6330242?v=3&amp;s=460" alt="作者的图片" />
    
    <h4 id="about-card-name">游</h4>
    
      <div id="about-card-bio">沉下心，多坚持</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        SRE
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        杭州
      </div>
    
  </div>
</div>

    

    
  
    <div id="cover" style="background-image:url('https://s2.ax1x.com/2020/01/09/lWSWLR.md.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="https://itech.red/js/script-pcw6v3xilnxydl1vddzazdverrnn9ctynvnxgwho987mfyqkuylcb1nlt.min.js"></script>


  
    <script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  

<script lang="javascript">
window.onload = updateMinWidth;
window.onresize = updateMinWidth;
document.getElementById("sidebar").addEventListener("transitionend", updateMinWidth);
function updateMinWidth() {
  var sidebar = document.getElementById("sidebar");
  var main = document.getElementById("main");
  main.style.minWidth = "";
  var w1 = getComputedStyle(main).getPropertyValue("min-width");
  var w2 = getComputedStyle(sidebar).getPropertyValue("width");
  var w3 = getComputedStyle(sidebar).getPropertyValue("left");
  main.style.minWidth = `calc(${w1} - ${w2} - ${w3})`;
}
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = 'https:\/\/itech.red\/2020\/12\/kubelet%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%8A\/';
          
            this.page.identifier = 'k8s_kubelet_source';
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'MTAyMC80ODIxMS8yNDcwNw==';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  




    
  </body>
</html>

