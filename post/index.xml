<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 平凡世界</title>
    <link>http://www.itech.red/post/index.xml</link>
    <description>Recent content in Posts on 平凡世界</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Apr 2017 19:10:59 +0800</lastBuildDate>
    <atom:link href="http://www.itech.red/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Ext2设计与实现(译)</title>
      <link>http://www.itech.red/2017/04/ext2%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E8%AF%91/</link>
      <pubDate>Thu, 06 Apr 2017 19:10:59 +0800</pubDate>
      
      <guid>http://www.itech.red/2017/04/ext2%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E8%AF%91/</guid>
      <description>

&lt;h2 id=&#34;ext2设计与实现&#34;&gt;Ext2设计与实现&lt;/h2&gt;

&lt;h3 id=&#34;1-介绍&#34;&gt;1、介绍&lt;/h3&gt;

&lt;p&gt;Linux第一版只支持Minix文件系统，Minix文件系统有两大亟待解决的限制：块地址存储在16位整型，最大文件大小为64MB；另外目录和文件名长度最大支持14个字符。&lt;/p&gt;

&lt;p&gt;我们设计与实现了两种新的文件系统:EXT 、 EXT2&lt;/p&gt;

&lt;p&gt;在这篇论文中，我们将简述Linux文件系统的历史，简单介绍Unix文件系统的基础概念；介绍Linux VFS层的实现并详细介绍EXT2内核代码与用户工具；最后，是Linux、BSD下EXT2性能测试对比。&lt;/p&gt;

&lt;h3 id=&#34;2-linux文件系统历史-略&#34;&gt;2、Linux文件系统历史（略）&lt;/h3&gt;

&lt;h3 id=&#34;3-文件系统概念&#34;&gt;3、文件系统概念&lt;/h3&gt;

&lt;p&gt;Linux文件系统的实现基于Unix操作系统通用概念：文件通过inodes来表示，目录是一种简单的文件包含许多列表项，设备是可以发起I/O请求的特殊文件。&lt;/p&gt;

&lt;h4 id=&#34;3-1-inode&#34;&gt;3.1 Inode&lt;/h4&gt;

&lt;p&gt;每个文件都使用inode结构体来表示，每个inode包含了描述文件元数据：文件类型、访问权限、所有者、时间戳、大小、数据块指针。分配给文件的数据块地址存储在文件的inode节点中，当用户对文件发起I/O请求时，内核代码将当前文件偏移量转为块号，使用该数字作为块地址表的索引来读写物理块，如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://occ9e8dkg.bkt.clouddn.com/ext2-inode.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;3-2-目录&#34;&gt;3.2 目录&lt;/h4&gt;

&lt;p&gt;目录按层次树结构组织，每一个目录可以包含文件和子目录。&lt;/p&gt;

&lt;p&gt;目录实现为一种特殊的文件。事实上，目录是一种包含列表项的文件，每一项包含一个inode号和一个文件名，当一个进程使用一个路径名时，内核代码会搜索目录查找对应的inode号，在路径文件名被转换为inode号后，inode结构会被存储到内存中用以后序请求。目录如下图：&lt;/p&gt;

&lt;h4 id=&#34;3-3-链接&#34;&gt;3.3 链接&lt;/h4&gt;

&lt;p&gt;Unix文件系统提出了链接的概念，若干个文件名可以关联到一个inode节点，inode节点包含一个存储链接数的域。增加一个链接会创建一个目录项并增加inode链接计数。当删除链接时，内核会递减链接计数，为0时删除inode。&lt;/p&gt;

&lt;p&gt;这种类型的链接称为硬链接，只能在一个文件系统中使用，且不能链接到一个目录，避免引起环路。&lt;/p&gt;

&lt;p&gt;另一种链接存在于大多数Unix系操作系统，符号链接：只包含文件名的简单文件，当内核inode转换时遇到符号链接，会将软链接文件内容替换链接名。因为软链接不包含inode，它可以跨文件系统，可以指向任何类型的文件，甚至不存在的文件。但软链接会占用磁盘空间、inode、在路径名到inode转换时引起额外消耗。&lt;/p&gt;

&lt;h4 id=&#34;3-4-设备文件&#34;&gt;3.4 设备文件&lt;/h4&gt;

&lt;p&gt;在Unix系操作系统，设备被当作特殊文件访问。一个设备文件并不占用文件系统空间，只作为设备驱动访问接口。&lt;/p&gt;

&lt;p&gt;有两类特殊文件：字符设备、块设备。主设备号决定类型，次设备号决定哪一个设备。&lt;/p&gt;

&lt;h3 id=&#34;4-vfs&#34;&gt;4 VFS&lt;/h3&gt;

&lt;p&gt;VFS是一个文件系统抽象层，定义了一个文件系统应该实现的操作，对上层屏蔽了底层不同文件系统的实现，一图概之：
&lt;img src=&#34;http://e2fsprogs.sourceforge.net/ext2-vfs.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;5-ext2&#34;&gt;5 EXT2&lt;/h3&gt;

&lt;h4 id=&#34;5-1-起因&#34;&gt;5.1 起因&lt;/h4&gt;

&lt;p&gt;修复EXT文件系统问题，提供一个强大的文件系统，实现unix文件语义并提供高级特性&lt;/p&gt;

&lt;h4 id=&#34;5-2-标准-ext2fs特性&#34;&gt;5.2 标准 ext2fs特性&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;支持标准Unix文件类型：普通文件、目录、设备文件、符号链接&lt;/li&gt;
&lt;li&gt;支持最大4TB文件系统&lt;/li&gt;
&lt;li&gt;长文件名：255字节，可扩展至1012&lt;/li&gt;
&lt;li&gt;为root保留空间以便修复&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;5-3-高级-ext2fs特性&#34;&gt;5.3 高级 ext2fs特性&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;属性继承&lt;/li&gt;
&lt;li&gt;软链接：目标名存储在inode中&lt;/li&gt;
&lt;li&gt;创建文件系统时可选择逻辑块大小&lt;/li&gt;
&lt;li&gt;fsck&lt;/li&gt;
&lt;li&gt;mount options&lt;/li&gt;
&lt;li&gt;Append-only files&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;5-4-物理结构&#34;&gt;5.4 物理结构&lt;/h4&gt;

&lt;p&gt;受BSD文件系统的影响，文件系统由块组构成，但块组并没有与磁盘的物理结构块绑定，因为现代驱动趋势是优化顺序访问和对操作系统隐藏物理结构。&lt;/p&gt;

&lt;p&gt;文件系统物理结构：
&lt;table border=&#34;&#34;&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;Boot&lt;br&gt;Sector&lt;/td&gt;
&lt;td&gt;Block&lt;br&gt;Group 1&lt;/td&gt;
&lt;td&gt;Block&lt;br&gt;Group 2&lt;/td&gt;
&lt;td&gt;&amp;hellip;&lt;br&gt;&amp;hellip;&lt;/td&gt;
&lt;td&gt;Block&lt;br&gt;Group N&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;&lt;/p&gt;

&lt;p&gt;每一个块组包含一份冗余的文件系统控制信息（超级块和文件系统描述信息），并包含一部分文件系统（块位图、inode位图、inode表、数据块）：
&lt;table border=&#34;&#34;&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;Super&lt;br&gt;Block&lt;/td&gt;
&lt;td&gt;FS&lt;br&gt;descriptors&lt;/td&gt;
&lt;td&gt;Block&lt;br&gt;Bitmap&lt;/td&gt;
&lt;td&gt;Inode&lt;br&gt;Bitmap&lt;/td&gt;
&lt;td&gt;Inode&lt;br&gt;Table&lt;/td&gt;
&lt;td&gt;Data&lt;br&gt;Blocks&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;&lt;/p&gt;

&lt;p&gt;使用block group提高系统可靠性，冗余超级块信息可以简化文件系统恢复；inode表与数据块一起存储提高寻道时间，提高性能。&lt;/p&gt;

&lt;p&gt;在ext2fs中，目录使用链表管理变长目录项，每一项包含inode号、记录项长度、文件名和文件名长度。通过变长目录项可以实现长文件名同时减少磁盘空间浪费，目录项结构如下：
&lt;table border=&#34;&#34;&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;inode number&lt;/td&gt;&lt;td&gt;entry length&lt;/td&gt;
&lt;td&gt;name length&lt;/td&gt;&lt;td&gt;filename&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;&lt;/p&gt;

&lt;h4 id=&#34;5-5-性能优化&#34;&gt;5.5 性能优化&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;预读：当读取一个块时，内核会请求连续的若干块，当读取下一个块时会从buffer cache读取&lt;/li&gt;
&lt;li&gt;分配优化： 块组的inode、data分配会在当前组中以减少寻道时间&lt;/li&gt;
&lt;li&gt;写时预分配&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;6-ext2fs-library-略&#34;&gt;6 Ext2fs library （略）&lt;/h3&gt;

&lt;p&gt;译自：&lt;a href=&#34;http://e2fsprogs.sourceforge.net/ext2intro.html&#34;&gt;http://e2fsprogs.sourceforge.net/ext2intro.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>认识sk_buff结构体</title>
      <link>http://www.itech.red/2017/04/%E8%AE%A4%E8%AF%86sk_buff%E7%BB%93%E6%9E%84%E4%BD%93/</link>
      <pubDate>Tue, 04 Apr 2017 19:07:48 +0800</pubDate>
      
      <guid>http://www.itech.red/2017/04/%E8%AE%A4%E8%AF%86sk_buff%E7%BB%93%E6%9E%84%E4%BD%93/</guid>
      <description>

&lt;h2 id=&#34;sk-buff结构体&#34;&gt;sk_buff结构体&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;struct sk_buff {
/* These two members must be first. */
struct sk_buff      *next;
struct sk_buff      *prev;
/* sk_buff双向链表 */
ktime_t         tstamp;
/* 报文接收时间戳，是个偏移量 */
struct sock     *sk;
/* 拥有此skb的socket */
struct net_device   *dev;
/* SKB收发的网络设备 */

/*
 * This is the control buffer. It is free to use for every
 * layer. Please put your private variables there. If you
 * want to keep them across layers you have to do a skb_clone()
 * first. This is owned by whoever has the skb queued ATM.
 */
char            cb[48] __aligned(8);
/* 控制缓存区，TCP、buletooth协议都有用到 */

unsigned long       _skb_refdst;
/* 指向dst_entry地址 */
unsigned int        len,
            data_len;
/* len:报文总长度，data_len:数据长度，仅当非线性存储报文时使用 */
__u16           mac_len,
            hdr_len;
/* mac_len:2层头长度，hdr_len:3层头长度*/
union {
    __wsum      csum;
    struct {
        __u16   csum_start;
        __u16   csum_offset;
    };
};
/* 校验和 */
__u32           priority;
/* 报文队列优先级 */
kmemcheck_bitfield_begin(flags1);
/* 位域开始指针 */
__u8            local_df:1,   //分片标志
            cloned:1,         //克隆标志，仅克隆SKB数据共享
            ip_summed:2,      //IP层校验和标志位 CHECKSUM_NONE需软件计算校验和 
            nohdr:1,          //报文头标志位，不需要头时置位
            nfctinfo:3;       //连接追踪，NAT中使用
__u8            pkt_type:3,   //报文类型：多播、广播、单播、非本地
            fclone:2,         //克隆状态
            ipvs_property:1,  //ip virtual server标志，4层负载均衡
            peeked:1,         //是否被查看标志
            nf_trace:1;       //netfilter trace标志
kmemcheck_bitfield_end(flags1);
__be16          protocol;     //协议

void            (*destructor)(struct sk_buff *skb);   //释放skb的回调函数

int         skb_iif;
//接收skb的接口索引
__u32           rxhash;
//源目的IP地址＋port计算hash值，保证SMP下相同flow被同一CPU处理，提高Cache命中率
__be16          vlan_proto;
//vlan协议 802.1q 、802.1ad
__u16           vlan_tci;
//vlan tag:包括低12位id，1位标志位，高3位优先级
__u16           queue_mapping;
//多队列网卡队列映射
kmemcheck_bitfield_begin(flags2);
__u8            pfmemalloc:1;    //标志位，pfmemalloc分配的skb
__u8            ooo_okay:1;      //out of order
__u8            l4_rxhash:1;     //4元组hash
__u8            wifi_acked_valid:1;  
__u8            wifi_acked:1;
__u8            no_fcs:1;        //使网卡SKB最后4字节为帧间序
__u8            head_frag:1;
/* Encapsulation protocol and NIC drivers should use
 * this flag to indicate to each other if the skb contains
 * encapsulated packet or not and maybe use the inner packet
 * headers if needed
 */
__u8            encapsulation:1;   //是否为封装报文，如vxlan
/* 7/9 bit hole (depending on ndisc_nodetype presence) */
kmemcheck_bitfield_end(flags2);
union {
    __u32       mark;            //标记skb，用于netfilter
    __u32       dropcount;          
    __u32       reserved_tailroom;
};

sk_buff_data_t      inner_transport_header;
sk_buff_data_t      inner_network_header;
sk_buff_data_t      inner_mac_header;
sk_buff_data_t      transport_header;
sk_buff_data_t      network_header;
sk_buff_data_t      mac_header;
/* These elements must be at the end, see alloc_skb() for details.  */
sk_buff_data_t      tail;       //指向数据尾  skb_put
sk_buff_data_t      end;        //指向缓存区尾
unsigned char       *head,      //指向缓存区头  
            *data;              //指向数据开头  skb_push skb_pull
unsigned int        truesize;   //总大小 包括skb结构体与block
atomic_t        users;  //引用计数
};
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;skb-shared-info结构体-位于block后-skb-end&#34;&gt;skb_shared_info结构体(位于block后，skb-&amp;gt;end)&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;260 struct skb_shared_info {
261     unsigned char   nr_frags;   //数组frags大小
262     __u8        tx_flags;       //tx标志位
263     unsigned short  gso_size;           
264     /* Warning: this field is not always filled in (UFO)! */
265     unsigned short  gso_segs;
266     unsigned short  gso_type;
267     struct sk_buff  *frag_list;      //分片
268     struct skb_shared_hwtstamps hwtstamps;
269     __be32          ip6_frag_id;
270
271     /*
272      * Warning : all fields before dataref are cleared in __alloc_skb()
273      */
274     atomic_t    dataref;    //引用计数
275
276     /* Intermediate layers must ensure that destructor_arg
277      * remains valid until skb destructor */
278     void *      destructor_arg;
279
280     /* must be last field, see pskb_expand_head() */
281     skb_frag_t  frags[MAX_SKB_FRAGS];
282 };
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Linux磁盘使用率100%异常排查</title>
      <link>http://www.itech.red/2017/04/linux%E7%A3%81%E7%9B%98%E4%BD%BF%E7%94%A8%E7%8E%87100%E5%BC%82%E5%B8%B8%E6%8E%92%E6%9F%A5/</link>
      <pubDate>Sat, 01 Apr 2017 18:00:54 +0800</pubDate>
      
      <guid>http://www.itech.red/2017/04/linux%E7%A3%81%E7%9B%98%E4%BD%BF%E7%94%A8%E7%8E%87100%E5%BC%82%E5%B8%B8%E6%8E%92%E6%9F%A5/</guid>
      <description>&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;

&lt;p&gt;线上堡垒机系统磁盘根目录/空间使用率100%导致无法添加账号，奇怪的是du查看实际只使用了8G多空间还有40多G，而df查看使用率却是100%，同事找过来让帮忙定位问题。&lt;/p&gt;

&lt;h2 id=&#34;du-h-max-depth-1-x-查看-目录磁盘占用情况-x排除挂载的其他磁盘&#34;&gt;du -h &amp;ndash;max-depth=1 -x 查看/目录磁盘占用情况(-x排除挂载的其他磁盘)&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://occ9e8dkg.bkt.clouddn.com/du.png&#34; alt=&#34;du&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;df查看-磁盘使用率在94&#34;&gt;df查看/磁盘使用率在94%&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://occ9e8dkg.bkt.clouddn.com/df.png&#34; alt=&#34;df&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;du与df机制对比&#34;&gt;du与df机制对比&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;df读取的是超级块的内容&lt;/li&gt;
&lt;li&gt;du是将所有文件对象大小加起来&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;两种机制的不同会造成两者结果不一致的地方，例如你在命令行下删除了一个文件，而这个文件正在被某个程序打开占用，实际上这个文件依然占用磁盘空间，只有在使用该文件的进程关闭时才真正清楚磁盘空间，这时du显示的数据会比df显示的值小。&lt;/p&gt;

&lt;h2 id=&#34;解决思路一&#34;&gt;解决思路一&lt;/h2&gt;

&lt;p&gt;通过lsof查看是否有已删除的文件仍被进程所使用：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;lsof | grep &#39;(deleted)&#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;找到某个大文件对应的进程，关闭该进程可以正确释放磁盘空间
但该方法在本例中并未解决问题！！！&lt;/p&gt;

&lt;h2 id=&#34;解决思路二&#34;&gt;解决思路二&lt;/h2&gt;

&lt;p&gt;在df的图中可以看到，根目录/下还挂载着/home与/home/admin是否有可能是&lt;strong&gt;原根目录下/home目录被挂载的/home覆盖&lt;/strong&gt;，而原/home目录的数据并未清楚，导致磁盘占用&lt;/p&gt;

&lt;p&gt;&lt;code&gt;mount -o bind / /mnt&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;在mnt下果然看到了原来/home目录，该目录下的废弃的用户账户占用磁盘40G空间！ 之前同事增加磁盘做文件系统粗心导致旧的数据未删除，给自己挖了一个坑！&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>