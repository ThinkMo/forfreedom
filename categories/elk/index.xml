<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Elk on 平凡世界</title>
    <link>http://www.itech.red/categories/elk/</link>
    <description>Recent content in Elk on 平凡世界</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Jan 2018 18:10:59 +0800</lastBuildDate>
    
	<atom:link href="http://www.itech.red/categories/elk/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ElasticSearch索引类型映射</title>
      <link>http://www.itech.red/2018/01/elasticsearch%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B%E6%98%A0%E5%B0%84/</link>
      <pubDate>Fri, 19 Jan 2018 18:10:59 +0800</pubDate>
      
      <guid>http://www.itech.red/2018/01/elasticsearch%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B%E6%98%A0%E5%B0%84/</guid>
      <description>最近接手维护了几个ELK集群，对接的是IaaS、PaaS服务日志，简单的ELK架构，通过filebeat采集日志，发送到logstash结构化日志然后发送到ElasticSearch，用户可以通过Kibana查看服务日志定位问题、做一些性能分析图表等，同时利用elastalert做日志报警。
在ElasticSearch须要对用户的索引建立合适的类型映射(尤其是int类型)，才可以在kibana中对数据进行分析，关于ES的映射类型可以看这里，需指出的是一旦某个field字段类型确定就很难更改该字段的类型(需reindex)。
Logstash将非结构化数据转化为结构化数据，通过JSON将数据发送给ElasticSearch，所有字段都会被当作string来处理，而ElasticSearch在自动判断字段类型建立映射这方面做的不足，与我们需求不符，那么如何正确建立索引类型映射呢？
一、通过Logstash的grok、mutate确定字段类型
 grok  根据grok官方文档，在grok正则表达式后可以添加一个数据类型，默认是string类型，如果你想使字段类型为int，你可以在表达式后加int，例如%{NUMBER:num:int}，那么num字段会从string类型变为int类型，目前只支持int和float。
 mutate   通过mutate可以将field转化为integer、float、string，例如：
 filter { mutate { convert =&amp;gt; { &amp;quot;num&amp;quot; =&amp;gt; &amp;quot;integer&amp;quot; } } }  二、ElasticSearch mapping template
映射(mappings)决定了一个字段(field)如何被ElasticSearch解释、存储，例如数据{&amp;ldquo;ip&amp;rdquo;:&amp;ldquo;223.5.5.5&amp;rdquo;}发送给ES，ES会将ip字段存储为string类型，而不是ip类型，不能做IP范围查询同时造成存储空间浪费、查询效率低等。不管在Logstash如何转换类型，ElasticSearch不会知道你的用意除非你正确映射。所有整型会存为long，小数会存为float或double，关于最小类型可以看这里，使用integer而不是long会有效的减少ELasticSearch负担。
 映射模版  编写模版文件my_template.json
 { &amp;quot;index_patterns&amp;quot; : &amp;quot;index*&amp;quot;, &amp;quot;version&amp;quot; : 1, &amp;quot;settings&amp;quot; : { &amp;quot;index.refresh_interval&amp;quot; : &amp;quot;5s&amp;quot; }, &amp;quot;mappings&amp;quot; : { &amp;quot;_default_&amp;quot; : { &amp;quot;properties&amp;quot;:{ &amp;quot;host&amp;quot;: { &amp;quot;type&amp;quot; : &amp;quot;string&amp;quot;}, &amp;quot;ip&amp;quot;: {&amp;quot;type&amp;quot; : &amp;quot;ip&amp;quot;}, .... } } } }  上传template.</description>
    </item>
    
    <item>
      <title>Logstash过滤插件grok正则解析</title>
      <link>http://www.itech.red/2017/10/logstash%E8%BF%87%E6%BB%A4%E6%8F%92%E4%BB%B6grok%E6%AD%A3%E5%88%99%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Tue, 10 Oct 2017 21:31:09 +0800</pubDate>
      
      <guid>http://www.itech.red/2017/10/logstash%E8%BF%87%E6%BB%A4%E6%8F%92%E4%BB%B6grok%E6%AD%A3%E5%88%99%E8%A7%A3%E6%9E%90/</guid>
      <description>Logstash过滤插件grok正则解析 一、grok介绍 grok是Logstash中用来解析非结构化日志数据，将日志转化为可查询的结构化数据的最佳方法，可以用来处理syslog日志、apache等webserver日志、mysql日志以及用户自定义日志。
Logstash自带有120多种预定义好的正则表达式方便用户使用，你可以在这里查看这些正则表达式，你也可以添加自己的匹配规则。
有两个网站可以帮助我们来构建正则表达式去匹配我们的日志：
 http://grokdebug.herokuapp.com http://grokconstructor.appspot.com (推荐)  二、grok基础 grok匹配模式语法为：%{SYNTAX:SEMANTIC:TYPE}
SYNTAX: 正则表达式、预定义的正则表达式名称
SEMANTIC: 标识符，标识匹配后的数据
TYPE: 可选的类型，目前支持int、float
例如：NUMBER可以匹配3.44，IP可以匹配：192.168.21.2
一个复杂的日志格式如下：
192.168.21.2 GET /index.html 15823 0.023  grok匹配模式可以为：
${IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}  更加实际的，该条日志可能来自一个文件：
input { file { path =&amp;gt; &amp;quot;/var/log/http.log&amp;quot; } } filter { grok { match =&amp;gt; { &amp;quot;message&amp;quot; =&amp;gt; &amp;quot;%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}&amp;quot; } } }  在grok过滤后，可以得到额外一下字段：
client: 192.168.21.2 method: GET request: /index.html bytes: 15823 duration: 0.</description>
    </item>
    
  </channel>
</rss>