<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>平凡世界</title>
    <link>https://itech.red/</link>
    <description>Recent content on 平凡世界</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Jul 2020 17:03:30 +0800</lastBuildDate>
    
	<atom:link href="https://itech.red/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>k8s 1.17.5高可用部署</title>
      <link>https://itech.red/2020/07/k8s-1.17.5%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Thu, 23 Jul 2020 17:03:30 +0800</pubDate>
      
      <guid>https://itech.red/2020/07/k8s-1.17.5%E9%AB%98%E5%8F%AF%E7%94%A8%E9%83%A8%E7%BD%B2/</guid>
      <description>k8s 1.17.5高可用部署 环境准备 K8S版本: 1.17.5
   IP 操作系统 主机配置 备注     192.168.0.2 debian9.5 4核8G control plane(apiserver/scheduler/controller/etcd)   192.168.0.3 debian9.5 4核8G control plane(apiserver/scheduler/controller/etcd)   192.168.0.4 debian9.5 4核8G control plane(apiserver/scheduler/controller/etcd)   192.168.0.5 debian9.5 4核8G node   192.168.0.6 debian9.5 4核8G node   192.168.0.7 debian9.5 4核8G node   59.111.230.7 LB X 负载均衡, 后端为控制节点(可换为keepalived VIP)    机器初始化(所有节点操作)  使用aliyun debian源 部署docker 18.09.9 (https://docs.</description>
    </item>
    
    <item>
      <title>友情链接</title>
      <link>https://itech.red/external_link/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://itech.red/external_link/</guid>
      <description>michael Java中间件、分布式、微服务 </description>
    </item>
    
    <item>
      <title>构建ElasticSearch集群之前</title>
      <link>https://itech.red/2018/12/%E6%9E%84%E5%BB%BAelasticsearch%E9%9B%86%E7%BE%A4%E4%B9%8B%E5%89%8D/</link>
      <pubDate>Wed, 12 Dec 2018 17:03:30 +0800</pubDate>
      
      <guid>https://itech.red/2018/12/%E6%9E%84%E5%BB%BAelasticsearch%E9%9B%86%E7%BE%A4%E4%B9%8B%E5%89%8D/</guid>
      <description>摘自designing the perfect elasticsearch cluster 
 本文包含了设计elasticsearch cluster需要了解的方方面面，本文不会告诉你如何设计一个完美的es集群。
  elasticsearch是一个搜索引擎，不是数据库，不会替代mysql
  elasticsearch是一个弹性搜索引擎，弹性体现在水平扩展、索引分片；elastic将索引拆分成多个分片存储在不同的host上，分片数量默认为5，需要根据实际workload调整以达到最优性能
  高可用设计
  elasticsearch集群包含一下4种节点类型： master nodes: 主节点 data node: 数据节点 http node: 查询节点 coordinating node: 协作节点 最小高可用集群设计： 1. 3数据中心 2. 3主节点，奇数个主节点防止脑裂，将3个主机点分散在各个数据中心 3. 2查询节点，在主节点数据中心各一个 4. 任意数量的数据节点 ES的分片分配算法允许分片分配在不同区域内，根据rack配置将主分片、备份分片分配在不同的区域中 cluster.routing.allocation.awareness.attributes: &amp;quot;rack_id&amp;quot; node.attr.rack_id: &amp;quot;dontsmokecrack&amp;quot;  理解luence: elasticsearch使用了luence库  1. 每个elasticsearch分片是一个luence索引，一个luence索引最大可包含2,147,483,519条记录。 2. luence将索引划分为多个段，luence顺序搜索这些段；当新写请求来时会创建段，写提交或关闭时， 段即不可变，有新记录添加到elasticsearch index时，luence会创建新的段，luence会不断的将小的段 合并成大的段。luence搜索段是串行的，所以段越多延迟越大。当luence合并时会占用CPU与I/O进而降 低index速度。 3. 当更新或删除文档时luence执行copy on write操作，删除只将文档标记为已删除，索引磁盘占用会 一直增长，除非整个索引删除。 4. luence执行merge时，会将两个段合并成一个新的段后再删除旧的段，merge要确保磁盘空间足够  硬件  CPU: 复杂查询 ElasticSearch主要通过thread_pools使用CPU资源，主要的thread_pool有generic、index、get、bulk、 search等，可用通过GET _nodes/thread_pool?</description>
    </item>
    
    <item>
      <title>Python GIL与线程安全</title>
      <link>https://itech.red/2018/08/python-gil%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/</link>
      <pubDate>Fri, 10 Aug 2018 15:17:59 +0800</pubDate>
      
      <guid>https://itech.red/2018/08/python-gil%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/</guid>
      <description>python GIL与多线程  GIL: Global Interpreter Lock(全局解释器锁)，python虚拟机一级的互斥机制，用来保护资源的互斥访问，尤其是python对象的引用计数。 python代码执行  获得GIL 执行代码直到被阻塞或N条指令执行之后(py3:超时时间)被python 虚拟机调度 释放GIL 何时挂起当前线程：被阻塞或N条指令执行之后(py3:超时时间15ms) 如何选择等待的线程进行调度：由底层操作系统决定  python多线程机制是在GIL基础上实现的 python的多线程机制建立在操作系统的原生线程的基础之上  Thread safe in python Python线程安全与传统的java、c有很大不同，python的很多操作都是原子的，例如sort函数本身是原子操作，不会被其他线程看到排序一半的list；而有一些操作不是原子的，例如+=
n=0 def add(): global n n += 1 import dis #将python byte code转为助记符号 dis.dis(add) 3 0 LOAD_GLOBAL 0 (n) 3 LOAD_CONST 1 (1) 6 INPLACE_ADD 7 STORE_GLOBAL 0 (n) 10 LOAD_CONST 0 (None) 13 RETURN_VALUE 操作步骤为：
 加载n到栈 加载常量n到栈 将两者相加 将结果付给n  由于操作不是原子的，python解释器可能在某一步被抢占，造成不一致的情况，执行以下代码，将不一定会得到100
threads = [] for i in range(100): t = threading.</description>
    </item>
    
    <item>
      <title>ElasticSearch配置滚动更新</title>
      <link>https://itech.red/2018/08/elasticsearch%E9%85%8D%E7%BD%AE%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0/</link>
      <pubDate>Mon, 06 Aug 2018 19:47:59 +0800</pubDate>
      
      <guid>https://itech.red/2018/08/elasticsearch%E9%85%8D%E7%BD%AE%E6%BB%9A%E5%8A%A8%E6%9B%B4%E6%96%B0/</guid>
      <description>起因 最近Logstash经常打印如下日志内容，虽然只是INFO级别的错误但还是引起了我的注意，大概意思是ES的bulk thread pool大小为32已经满负荷，队列也满了，所以拒绝了Logstash的bulk请求
[2018-06-23T08:00:47,281][INFO ][logstash.outputs.elasticsearch] retrying failed action with response code: 429 ({&amp;quot;type&amp;quot;=&amp;gt;&amp;quot;es_rejected_execution_exception&amp;quot;, &amp;quot;reason&amp;quot;=&amp;gt;&amp;quot;rejected execution of org.elasticsearch.transport.TransportService$7@177d229b on EsThreadPoolExecutor[bulk, queue capacity = 1000, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@66a1a8c3[Running, pool size = 32, active threads = 32, queued tasks = 1019, completed tasks = 832616617]]&amp;quot;}) 解决思路  扩大处理bulk的thread pool线程数量  当前使用的服务器CPU核数为176(cat /proc/cpuinfo)，而在ES源码中为了避免引起Java oom线程数会取min(32, 核数)，所以造成默认的thread_pool.bulk.size为32，为了扩大线程容量需在ES中添加以下配置 processors: 96 thread_pool.bulk.size: 96  增加等待队列长度  thread_pool.bulk.queue_size: 3000 更新配置 这些配置不能通过ES Setting API来更改，只能通过滚动重启的方式，下面简单记录下过程
 禁止分配分片  curl -X PUT &amp;quot;ES_HOST:9200/_cluster/settings&amp;quot; -H &#39;Content-Type: application/json&#39; -d&#39; { &amp;quot;transient&amp;quot;: { &amp;quot;cluster.</description>
    </item>
    
    <item>
      <title>ELK集群2.x到5.6升级记录</title>
      <link>https://itech.red/2018/04/elk%E9%9B%86%E7%BE%A42.x%E5%88%B05.6%E5%8D%87%E7%BA%A7%E8%AE%B0%E5%BD%95/</link>
      <pubDate>Mon, 02 Apr 2018 20:10:59 +0800</pubDate>
      
      <guid>https://itech.red/2018/04/elk%E9%9B%86%E7%BE%A42.x%E5%88%B05.6%E5%8D%87%E7%BA%A7%E8%AE%B0%E5%BD%95/</guid>
      <description>考虑到目前使用的ELK集群版本与开源版本的版本差距有点大，而ELK5.6相较2.3版本性能有较大提升，尤其是Logstash grok插件，最近对测试环境的两个ELK集群进行了升级，对升级过程进行一个记录；升级主要参考了官方文档
当前系统运行版本  filebeat：1.2.3 kibana：4.5.1 logstash：2.3.2 elasticsearch：2.3.3 JVM: 1.7  升级顺序  jvm(略) elasticsearch kibana logstash beats  升级Elasticsearch 升级之前  升级前使用Elasticsearch Migration Plugin查看潜在问题 最好先在测试环境升级ELK 在升级之前先备份数据  升级（跨大版本整个集群需重启）   禁止自动分配分片，在停止elasticsearch时减少不必要的I/O
curl -XPUT &#39;localhost:9200/_cluster/settings?pretty&#39; -H &#39;Content-Type: application/json&#39; -d&#39;{ &amp;quot;persistent&amp;quot;: {&amp;quot;cluster.routing.allocation.enable&amp;quot;: &amp;quot;none&amp;quot;} }&#39;   同步刷新以加快分片恢复
curl -XPOST &#39;localhost:9200/_flush/synced?pretty&#39;  停止并升级各个节点（安装新的rpm或deb，更新配置文件，配置文件有较大改动）
/etc/init.d/elasticsearch stop apt-get pruge elasticsearch(所有deb包已在本地apt源中,删除原配置文件) apt-get install elasticsearch=5.6.5   升级插件（需删除旧的插件）
/usr/share/elasticsearch/bin/elasticsearch-plubin remove license /usr/share/elasticsearch/bin/elasticsearch-plubin remove marvel /usr/share/elasticsearch/bin/elasticsearch-plubin install x-pack   启动集群各个节点，保证所有节点均加入集群(优先启动master node)</description>
    </item>
    
    <item>
      <title>ElasticSearch索引类型映射</title>
      <link>https://itech.red/2018/01/elasticsearch%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B%E6%98%A0%E5%B0%84/</link>
      <pubDate>Fri, 19 Jan 2018 18:10:59 +0800</pubDate>
      
      <guid>https://itech.red/2018/01/elasticsearch%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B%E6%98%A0%E5%B0%84/</guid>
      <description>最近接手维护了几个ELK集群，对接的是IaaS、PaaS服务日志，简单的ELK架构，通过filebeat采集日志，发送到logstash结构化日志然后发送到ElasticSearch，用户可以通过Kibana查看服务日志定位问题、做一些性能分析图表等，同时利用elastalert做日志报警。
在ElasticSearch须要对用户的索引建立合适的类型映射(尤其是int类型)，才可以在kibana中对数据进行分析，关于ES的映射类型可以看这里，需指出的是一旦某个field字段类型确定就很难更改该字段的类型(需reindex)。
Logstash将非结构化数据转化为结构化数据，通过JSON将数据发送给ElasticSearch，所有字段都会被当作string来处理，而ElasticSearch在自动判断字段类型建立映射这方面做的不足，与我们需求不符，那么如何正确建立索引类型映射呢？
一、通过Logstash的grok、mutate确定字段类型
  grok
根据grok官方文档，在grok正则表达式后可以添加一个数据类型，默认是string类型，如果你想使字段类型为int，你可以在表达式后加int，例如%{NUMBER:num:int}，那么num字段会从string类型变为int类型，目前只支持int和float。
  mutate
通过mutate可以将field转化为integer、float、string，例如：
filter { mutate { convert =&amp;gt; { &amp;quot;num&amp;quot; =&amp;gt; &amp;quot;integer&amp;quot; } } }   二、ElasticSearch mapping template
映射(mappings)决定了一个字段(field)如何被ElasticSearch解释、存储，例如数据{&amp;ldquo;ip&amp;rdquo;:&amp;ldquo;223.5.5.5&amp;rdquo;}发送给ES，ES会将ip字段存储为string类型，而不是ip类型，不能做IP范围查询同时造成存储空间浪费、查询效率低等。**不管在Logstash如何转换类型，ElasticSearch不会知道你的用意除非你正确映射。**所有整型会存为long，小数会存为float或double，关于最小类型可以看这里，使用integer而不是long会有效的减少ELasticSearch负担。
  映射模版
编写模版文件my_template.json
{ &amp;quot;index_patterns&amp;quot; : &amp;quot;index*&amp;quot;, &amp;quot;version&amp;quot; : 1, &amp;quot;settings&amp;quot; : { &amp;quot;index.refresh_interval&amp;quot; : &amp;quot;5s&amp;quot; }, &amp;quot;mappings&amp;quot; : { &amp;quot;_default_&amp;quot; : { &amp;quot;properties&amp;quot;:{ &amp;quot;host&amp;quot;: { &amp;quot;type&amp;quot; : &amp;quot;string&amp;quot;}, &amp;quot;ip&amp;quot;: {&amp;quot;type&amp;quot; : &amp;quot;ip&amp;quot;}, .... } } } }   上传template.</description>
    </item>
    
    <item>
      <title>Logstash过滤插件grok正则解析</title>
      <link>https://itech.red/2017/10/logstash%E8%BF%87%E6%BB%A4%E6%8F%92%E4%BB%B6grok%E6%AD%A3%E5%88%99%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Tue, 10 Oct 2017 21:31:09 +0800</pubDate>
      
      <guid>https://itech.red/2017/10/logstash%E8%BF%87%E6%BB%A4%E6%8F%92%E4%BB%B6grok%E6%AD%A3%E5%88%99%E8%A7%A3%E6%9E%90/</guid>
      <description>Logstash过滤插件grok正则解析 一、grok介绍 grok是Logstash中用来解析非结构化日志数据，将日志转化为可查询的结构化数据的最佳方法，可以用来处理syslog日志、apache等webserver日志、mysql日志以及用户自定义日志。
Logstash自带有120多种预定义好的正则表达式方便用户使用，你可以在这里查看这些正则表达式，你也可以添加自己的匹配规则。
有两个网站可以帮助我们来构建正则表达式去匹配我们的日志：
 http://grokdebug.herokuapp.com http://grokconstructor.appspot.com (推荐)  二、grok基础 grok匹配模式语法为：%{SYNTAX:SEMANTIC:TYPE}
SYNTAX: 正则表达式、预定义的正则表达式名称
SEMANTIC: 标识符，标识匹配后的数据
TYPE: 可选的类型，目前支持int、float
例如：NUMBER可以匹配3.44，IP可以匹配：192.168.21.2
一个复杂的日志格式如下：
192.168.21.2 GET /index.html 15823 0.023 grok匹配模式可以为：
${IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration} 更加实际的，该条日志可能来自一个文件：
input { file { path =&amp;gt; &amp;quot;/var/log/http.log&amp;quot; } } filter { grok { match =&amp;gt; { &amp;quot;message&amp;quot; =&amp;gt; &amp;quot;%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}&amp;quot; } } } 在grok过滤后，可以得到额外一下字段：
client: 192.168.21.2 method: GET request: /index.html bytes: 15823 duration: 0.023 grok中的正则表达式 Grok采用了Oniguruma正则表达式库，在on the Oniguruma site看到支持的正则语法。</description>
    </item>
    
    <item>
      <title>Ext2设计与实现(译)</title>
      <link>https://itech.red/2017/04/ext2%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E8%AF%91/</link>
      <pubDate>Thu, 06 Apr 2017 19:10:59 +0800</pubDate>
      
      <guid>https://itech.red/2017/04/ext2%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0%E8%AF%91/</guid>
      <description>Ext2设计与实现 1、介绍 Linux第一版只支持Minix文件系统，Minix文件系统有两大亟待解决的限制：块地址存储在16位整型，最大文件大小为64MB；另外目录和文件名长度最大支持14个字符。
我们设计与实现了两种新的文件系统:EXT 、 EXT2
在这篇论文中，我们将简述Linux文件系统的历史，简单介绍Unix文件系统的基础概念；介绍Linux VFS层的实现并详细介绍EXT2内核代码与用户工具；最后，是Linux、BSD下EXT2性能测试对比。
2、Linux文件系统历史（略） 3、文件系统概念 Linux文件系统的实现基于Unix操作系统通用概念：文件通过inodes来表示，目录是一种简单的文件包含许多列表项，设备是可以发起I/O请求的特殊文件。
3.1 Inode 每个文件都使用inode结构体来表示，每个inode包含了描述文件元数据：文件类型、访问权限、所有者、时间戳、大小、数据块指针。分配给文件的数据块地址存储在文件的inode节点中，当用户对文件发起I/O请求时，内核代码将当前文件偏移量转为块号，使用该数字作为块地址表的索引来读写物理块，如下图所示：
3.2 目录 目录按层次树结构组织，每一个目录可以包含文件和子目录。
目录实现为一种特殊的文件。事实上，目录是一种包含列表项的文件，每一项包含一个inode号和一个文件名，当一个进程使用一个路径名时，内核代码会搜索目录查找对应的inode号，在路径文件名被转换为inode号后，inode结构会被存储到内存中用以后序请求。目录如下图：
3.3 链接 Unix文件系统提出了链接的概念，若干个文件名可以关联到一个inode节点，inode节点包含一个存储链接数的域。增加一个链接会创建一个目录项并增加inode链接计数。当删除链接时，内核会递减链接计数，为0时删除inode。
这种类型的链接称为硬链接，只能在一个文件系统中使用，且不能链接到一个目录，避免引起环路。
另一种链接存在于大多数Unix系操作系统，符号链接：只包含文件名的简单文件，当内核inode转换时遇到符号链接，会将软链接文件内容替换链接名。因为软链接不包含inode，它可以跨文件系统，可以指向任何类型的文件，甚至不存在的文件。但软链接会占用磁盘空间、inode、在路径名到inode转换时引起额外消耗。
3.4 设备文件 在Unix系操作系统，设备被当作特殊文件访问。一个设备文件并不占用文件系统空间，只作为设备驱动访问接口。
有两类特殊文件：字符设备、块设备。主设备号决定类型，次设备号决定哪一个设备。
4 VFS VFS是一个文件系统抽象层，定义了一个文件系统应该实现的操作，对上层屏蔽了底层不同文件系统的实现，一图概之：
5 EXT2 5.1 起因 修复EXT文件系统问题，提供一个强大的文件系统，实现unix文件语义并提供高级特性
5.2 标准 ext2fs特性  支持标准Unix文件类型：普通文件、目录、设备文件、符号链接 支持最大4TB文件系统 长文件名：255字节，可扩展至1012 为root保留空间以便修复  5.3 高级 ext2fs特性  属性继承 软链接：目标名存储在inode中 创建文件系统时可选择逻辑块大小 fsck mount options Append-only files  5.4 物理结构 受BSD文件系统的影响，文件系统由块组构成，但块组并没有与磁盘的物理结构块绑定，因为现代驱动趋势是优化顺序访问和对操作系统隐藏物理结构。
文件系统物理结构：
每一个块组包含一份冗余的文件系统控制信息（超级块和文件系统描述信息），并包含一部分文件系统（块位图、inode位图、inode表、数据块）：
使用block group提高系统可靠性，冗余超级块信息可以简化文件系统恢复；inode表与数据块一起存储提高寻道时间，提高性能。
在ext2fs中，目录使用链表管理变长目录项，每一项包含inode号、记录项长度、文件名和文件名长度。通过变长目录项可以实现长文件名同时减少磁盘空间浪费，目录项结构如下：
5.5 性能优化  预读：当读取一个块时，内核会请求连续的若干块，当读取下一个块时会从buffer cache读取 分配优化： 块组的inode、data分配会在当前组中以减少寻道时间 写时预分配  6 Ext2fs library （略） 译自：http://e2fsprogs.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://itech.red/resume/</link>
      <pubDate>Sat, 01 Apr 2017 18:00:54 +0800</pubDate>
      
      <guid>https://itech.red/resume/</guid>
      <description>个人信息  游/男/1988 硕士/电子科技大学计算机与工程学院 英语能力:CET-6 邮箱:tryit0714@gmail.com  工作经历 淘宝(中国)软件软件有限公司（2015年7月～至今） 系统工程师
Kernel/OS自动化测试平台 (2016.11~至今)
集团跳板机系统、大盘与高危审计项目 (2016.4-2016.9)
智能网卡项目 （2015.9-2016.3）
Linux进程级网络流量监控（2015.7）
兴趣方向  Linux下C/C++环境编程、网络编程 Linux内核网络与文件系统 分布式系统 熟悉Java、Python、Go、Shell  </description>
    </item>
    
    <item>
      <title>springmvc实现导出数据excel</title>
      <link>https://itech.red/2016/11/springmvc%E5%AE%9E%E7%8E%B0%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AEexcel/</link>
      <pubDate>Wed, 23 Nov 2016 18:47:34 +0800</pubDate>
      
      <guid>https://itech.red/2016/11/springmvc%E5%AE%9E%E7%8E%B0%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AEexcel/</guid>
      <description>springmvc实现导出数据excel
最近在项目中要实现将数据导出为excel的功能，研究了下目前springmvc框架下excel导出的方式，在spring 4.3中使用AbstractXlsView来实现，AbstractExcelView已被弃用；但这里介绍的是直接用apache poi实现的一种方式。
 model如下  package red.itech.blog.dao.model; import java.util.Date; /** * Created by you on 16/10/28. */ public class Blog { private String author; private Date createdAt; private String title; private long count; public Blog(){} public Blog(String author, Date createdAt, String title, long count){ this.author = author; this.count = count; this.createdAt = createdAt; this.title =title; } public void setAuthor(String author) { this.author = author; } public void setCreatedAt(Date createdAt) { this.</description>
    </item>
    
    <item>
      <title>Spring＋Mybatis＋Velocity项目搭建</title>
      <link>https://itech.red/2016/09/springmybatisvelocity%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Wed, 28 Sep 2016 15:43:54 +0800</pubDate>
      
      <guid>https://itech.red/2016/09/springmybatisvelocity%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/</guid>
      <description>Spring＋Mybatis＋Velocity项目搭建
一、开发工具
 JDK 1.8.0_91 Intellij IDEA 15.0.6 Mysql 5.5.44 Maven 3  二、新建工程
  新建Maven工程，不选Create from archtype提供的工程模版，为了学习从头开始配置工程，点击next设置工程坐标，然后一路到finish。  &amp;lt;groupId&amp;gt;red.itech&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;blogDemo&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.0-SNAPSHOT&amp;lt;/version&amp;gt;    如果使用git开发，可以新建.gitignore文件，使git忽略idea自动生成的文件（.ignore插件可以帮助生成.gitignore），项目git初始化
# Created by .ignore support plugin (hsz.mobi) .gitignore ### OSX template *.DS_Store # IntelliJ project files .idea *.iml out target gen### Java template *.class # Package Files # *.jar *.war *.ear ` 三、Spring MVC
  编辑pom.xml添加Spring MVC、servlet依赖如下：
 &amp;lt;dependencies&amp;gt; &amp;lt;!-- spring --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.</description>
    </item>
    
    <item>
      <title>理解UML类图关系</title>
      <link>https://itech.red/2016/08/%E7%90%86%E8%A7%A3uml%E7%B1%BB%E5%9B%BE%E5%85%B3%E7%B3%BB/</link>
      <pubDate>Fri, 26 Aug 2016 16:51:34 +0800</pubDate>
      
      <guid>https://itech.red/2016/08/%E7%90%86%E8%A7%A3uml%E7%B1%BB%E5%9B%BE%E5%85%B3%E7%B3%BB/</guid>
      <description>理解UML类图关系
1、依赖(Dependency)
  关系：uses temporarily，使用关系，作为局部变量、方法参数或者对静态方法的调用
  代码示例：
 import B; public class A{ public void method1(B b) { // ... } public void method2() { B tempB = new B(); // ... } }    图示(一套带箭头的虚线表示)：
  2、聚合(Aggregation)
  关系：is part of，整体与部分的关系，作为成员变量
  代码：
 import Engine; public class Car{ private Engine engine; publilc Engine getEngine(){ return engine; } }    图示(一条带空心菱形箭头的直线表示)：</description>
    </item>
    
    <item>
      <title></title>
      <link>https://itech.red/papare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://itech.red/papare/</guid>
      <description>基础 算法与数据结构 数据结构  数组与链表 栈与队列 优先队列 树 哈希表 并差集 Trie树 布隆过滤器: 可以确定不存在 LRU cache 图  skiplist 随机化数据结构log(n)
插入：插入时先查找到当前插入节点的前缀，随机生产新节点的level，从level到底层逐步更新前缀指针
若干年前的实现
rbtree  每个节点要么是黑色，要么是红色。 根节点是黑色。 每个叶子节点（NIL）是黑色。 每个红色结点的两个子结点一定都是黑色。 任意一结点到每个叶子结点的路径都包含数量相同的黑结点。  若干年前的实现
算法  贪心 哈夫曼编码、最短生成树prim and cruskarl 递归 遍历 深度优先与广度优先搜索 分治法 动态规划  数组与链表  基本操作时间复杂度     op 数组array 链表linked lsit     access O(1) O(n)   insert O(n) O(1)   delete O(n) O(1)     常见题目   翻转链表 判断链表是否有环 (快慢指针)  栈与队列  栈 FILO 队列 FIFO 常见题目   括号匹配 队列实现栈(写直接入队列，读数据入另一队列剩1个即为栈顶)，栈实现队列(写入数据直接压栈，读时排空一个栈，取栈顶)  优先队列（heap）  正常入，按优先级出 操作时间复杂度 斐波那契堆是一系列无序树的集合，每棵树是一个最小堆，满足最小堆的性质     op binary fibonacci     find-min Θ(1) Θ(1)   delete-min Θ(log n) O(log n)   insert O(log n) Θ(1)   merge Θ(n) Θ(1)     常见题目   kth largest in stream 滑动窗口  哈希表  2sum 3sum  树与二叉树  binary search tree 验证: 带上下界递归遍历 最小公共祖先  递归与分治  Pow(x, n) 一组数的大多数  贪心算法 问题能够分解成子问题，子问题的最优解能递推到最终问题的最优解</description>
    </item>
    
  </channel>
</rss>